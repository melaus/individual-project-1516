Project Title: Using Machine-learning Techniques to Increase the Effiency of Kinect Fusion Reconstructions

1 Problem Description
Kinect Fusion is a Micrsoft Research project that enables rapid and detailed 3D reconstructions, both real-time and off-line, through scanning an object and merging the depth data of the many frames together, with the help of a Kinect camera [1][2]. 

A few research projects from Microsoft demonstrates some interesting ideas about Kinect Fusion. For example, SemanticPaint [3] provides a real-time augmented experience where users can label and segment through the combination of commands, Kinect Fusion and object recognition. Other researches include non-rigid scene reconstruction [4], dense surface mapping [5] and a Master's thesis on building-scale interior reconstruction. [6] Similar information to this will be become handy when attempting this project. 

One issue with Kinect Fusion is that it does not recognise objects it has seen before. This means that seeing something again will require reconstruction, wasting time for reconstructing things it should have known.

This project aims to solve this, so to speed up reconstruction of objects seen before in a different scenario with the help of classifiers. For instance, many rooms at the University share the same equipment across multiple rooms. Rather than having to re-scan and reconstruct an object encountered before, a newly reconstructed item should be stored, so that it can be recognised later by the classifiers at another scene. When encountering a new scene the same object in it, only a quick scan from one angle is needed to fill in full, detailed scans of objects seen before. This shortens the time and minimise the effort required to reconstruct a new scene with identical objects, but provides a detailed reconstruction at the same time.

Moreover, the classifier should locate the best match at all times. This could help provide a fast reconstructing of new scenes with new objects. The best matched item could be put in place with a one-angled quick scan. If it is deemed good enough, the room reconstruction can be used as is, without the need of further scanning. If further scanning of an object is required, it can then replace an object of the reconstructed scene at a later time.

1.3 Aim
The aim is to quickly reconstruct a scene without needing to re-scan each object in detail again to obtain a well-reconstructed scene, by using classifiers or other appropriate machine-learning techniques. 

1.4 Objectives
1.4.1 Main Objectives
1 Develop one or a set of classifiers that can accurately identify a given object or being able to find the next best match if it does not exist.
2 Vigorously train and test the classifier with many scans of similar objects to improve its accuracy  
3 Design and implement algorithms to locate potential object posititions and the partial information
4 Design and implement algorithms to use the classifier on the partial information of objects to find the best match

1.4.2 Stretched Objectives
These objectives are nice to have if they can be done on top of the main objectives, but it is expected these will not be achievable with the limited time and scope of this project
* Adapt and develop a real-time version where objects are being put in place right at the scene
* Provide an augmented reality experience, one that is similar to 

2 Requirements Specification

2.1 Machine-learning

2.2 Technologies
1. The prototype must be done in a simple language that allows quick iterations.
* R or Python (with the libraries such as pyML, numpy or scikit-learn) can be used to produce the initial prototypes, and will probably end up in a Python implementation for better extendability and portability.
* Use the NYU Kinect Dataset as a starting point to create this prototype
2. 

2.3 Hardware
1. A relatively powerful Windows-based computer should be used, especially when capturing Kinect scans for Kinect Fusion's reconstructed data. 
* It needs to have an important 


3 Project Plan

4 Resources
4.1 Hardware
4.2 Software
1. R/ Python Environment
I will need to ensure that I have all packages I would like to test out installed.  

(1)https://msdn.microsoft.com/en-us/library/dn188670.aspx
(2)http://blogs.msdn.com/b/kinectforwindows/archive/2013/03/06/kinect-fusion-demonstrated-at-microsoft-research-techfest-coming-soon-to-sdk.aspx
(3)http://www.winbeta.org/news/microsoft-research-debuts-another-project-semantic-paint
(4)http://homes.cs.washington.edu/~newcombe/papers/DynamicFusion.pdf
(5)http://homes.cs.washington.edu/~newcombe/papers/newcombe_etal_ismar2011.pdf
(6)http://www.doc.ic.ac.uk/teaching/distinguished-projects/2014/n.hambuechen.pdf
(7)http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html
